{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "\u001b[1;33m[Open3D WARNING] The number of points is 0 when creating axis-aligned bounding box.\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "import os; os.environ[\"DISPLAY\"] = \"localhost:10.0\";\n",
    "os.environ[\"__GLX_VENDOR_LIBRARY_NAME\"] = \"mesa\"; # export DISPLAY=localhost:10.0 __GLX_VENDOR_LIBRARY_NAME=mesa  # See: https://superuser.com/questions/106056/force-software-based-opengl-rendering-on-ubuntu\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\";\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from trimesh_render import lookAt\n",
    "\n",
    "import pytransform3d.transformations as pt\n",
    "\n",
    "class PointCloudViewer:\n",
    "    def __init__(self):\n",
    "        self.origin = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1, origin=[0, 0, 0])\n",
    "        self.eef = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1, origin=[0, 0, 0])\n",
    "        self.eef_T_inv = np.eye(4)\n",
    "        self.pcd = o3d.geometry.PointCloud()\n",
    "\n",
    "        # Initialize the pointcloud viewer\n",
    "        self.vis = o3d.visualization.Visualizer()\n",
    "        self.vis.create_window(window_name=\"Point Cloud\")\n",
    "\n",
    "        self.vis.add_geometry(self.origin)\n",
    "        self.vis.add_geometry(self.eef)\n",
    "        self.vis.add_geometry(self.pcd)\n",
    "\n",
    "        self.vis.get_render_option().point_size = 1\n",
    "        # self.vis.get_render_option().background_color = np.asarray([0, 0, 0])\n",
    "\n",
    "        view_control = self.vis.get_view_control()\n",
    "        view_control.set_constant_z_far(1000)\n",
    "\n",
    "        # Retrieve the camera parameters\n",
    "        camera_params = view_control.convert_to_pinhole_camera_parameters()\n",
    "        # Set the extrinsic parameters, yz_flip is for Open3D camera configuration\n",
    "        # camera_pose = lookAt(eye=np.array([0., 0., -1.]), target=np.array([0. ,0., 0.]), up=np.array([0.0, -1.0, 0.0]), yz_flip=True)\n",
    "        camera_pose = lookAt(eye=np.array([0., -1., -1.]), target=np.array([0. ,0., 0.]), up=np.array([0.0, -1.0, 0.0]), yz_flip=True)\n",
    "        camera_params.extrinsic = np.linalg.inv(camera_pose)\n",
    "        # Set the camera parameters\n",
    "        view_control.convert_from_pinhole_camera_parameters(camera_params)\n",
    "        \n",
    "        frame = self.vis.capture_screen_float_buffer(do_render=True)\n",
    "        frame = np.asarray(frame)\n",
    "        self.video_writer = cv2.VideoWriter(\"demo.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), 60, (frame.shape[1], frame.shape[0]))\n",
    "    \n",
    "    def update_vis(self):\n",
    "        # Update the visualizer\n",
    "        self.vis.poll_events()\n",
    "        self.vis.update_renderer()\n",
    "    \n",
    "    def update(self, image_array, depth_array, intrinsics, Teef2cam):\n",
    "        im_rgb = o3d.geometry.Image(cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB))\n",
    "        im_d = o3d.geometry.Image(depth_array)\n",
    "\n",
    "        im_rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "            im_rgb,\n",
    "            im_d,\n",
    "            depth_scale=1000.0,\n",
    "            convert_rgb_to_intensity=False\n",
    "        )\n",
    "\n",
    "        height, width, _ = image_array.shape\n",
    "\n",
    "        new_pcd = o3d.geometry.PointCloud.create_from_rgbd_image(im_rgbd, o3d.camera.PinholeCameraIntrinsic(width=width, height=height, intrinsic_matrix=intrinsics))\n",
    "\n",
    "        # new_pcd.transform(CAMERA_TO_WORLD)\n",
    "\n",
    "        self.pcd.points = new_pcd.points\n",
    "        self.pcd.colors = new_pcd.colors\n",
    "        self.vis.update_geometry(self.pcd)\n",
    "\n",
    "        self.eef.transform(self.eef_T_inv)\n",
    "        self.eef.transform(Teef2cam)\n",
    "        self.eef_T_inv = pt.invert_transform(Teef2cam)\n",
    "        self.vis.update_geometry(self.eef)\n",
    "\n",
    "        self.update_vis()\n",
    "        \n",
    "        # Capture the current frame\n",
    "        frame = self.vis.capture_screen_float_buffer(do_render=True)\n",
    "        frame = np.asarray(frame)\n",
    "        \n",
    "        # Convert to uint8 and BGR format for OpenCV\n",
    "        frame = (frame * 255).astype(np.uint8)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Write frame to video\n",
    "        self.video_writer.write(frame)\n",
    "    \n",
    "    def close(self):\n",
    "        self.video_writer.release()\n",
    "        self.vis.destroy_window()\n",
    "\n",
    "viewer = PointCloudViewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24044\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "droid3d_anno_path = \"droid\"\n",
    "\n",
    "with open(droid3d_anno_path + \"/cam2base_extrinsics.json\") as f:\n",
    "    cam2base_extrinsics = json.load(f)\n",
    "\n",
    "with open(droid3d_anno_path + \"/cam2base_extrinsic_superset.json\") as f:\n",
    "    cam2base_extrinsic_superset = json.load(f)\n",
    "\n",
    "with open(droid3d_anno_path + \"/droid_language_annotations.json\") as f:\n",
    "    droid_language_annotations = json.load(f)\n",
    "\n",
    "print(len(cam2base_extrinsic_superset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59740\n",
      "uuid IPRL+7790ec0a+2023-06-27-20h-57m-09s not in cam2base_extrinsic_superset\n",
      "uuid IPRL+7790ec0a+2023-06-27-20h-24m-51s not in cam2base_extrinsic_superset\n",
      "IPRL+7790ec0a+2023-06-27-21h-02m-21s\n",
      "IPRL/success/2023-06-27/Tue_Jun_27_21:02:21_2023\n",
      "{'uuid': 'IPRL+7790ec0a+2023-06-27-21h-02m-21s', 'lab': 'IPRL', 'user': 'Marion Lepert', 'user_id': '7790ec0a', 'date': '2023-06-27', 'timestamp': '2023-06-27-21h-02m-21s', 'hdf5_path': 'success/2023-06-27/Tue_Jun_27_21:02:21_2023/trajectory.h5', 'building': '775 Roble', 'scene_id': 8351259745, 'success': True, 'robot_serial': 'panda-295341-1325480', 'r2d2_version': '1.3', 'current_task': 'Open or close hinged object (ex: hinged door, microwave, oven, book, dryer, toilet, box)', 'trajectory_length': 153, 'wrist_cam_serial': '12391924', 'ext1_cam_serial': '21582473', 'ext2_cam_serial': '28221883', 'wrist_cam_extrinsics': [0.32085092844058694, 0.061907514889166, 0.4160269019638068, 2.780198025634674, -0.21272213182917477, 1.7303129617793613], 'ext1_cam_extrinsics': [0.4133658918373677, 0.5191669411163002, 0.34488415138807543, -1.8749857605155331, 0.002304947622426168, -2.417060550579326], 'ext2_cam_extrinsics': [0.41219764578398044, -0.3362463845488745, 0.3913281515308852, -1.6775540904351778, -0.02166973075098544, -0.9203954685179273], 'wrist_svo_path': 'success/2023-06-27/Tue_Jun_27_21:02:21_2023/recordings/SVO/12391924.svo', 'wrist_mp4_path': 'success/2023-06-27/Tue_Jun_27_21:02:21_2023/recordings/MP4/12391924.mp4', 'ext1_svo_path': 'success/2023-06-27/Tue_Jun_27_21:02:21_2023/recordings/SVO/21582473.svo', 'ext1_mp4_path': 'success/2023-06-27/Tue_Jun_27_21:02:21_2023/recordings/MP4/21582473.mp4', 'ext2_svo_path': 'success/2023-06-27/Tue_Jun_27_21:02:21_2023/recordings/SVO/28221883.svo', 'ext2_mp4_path': 'success/2023-06-27/Tue_Jun_27_21:02:21_2023/recordings/MP4/28221883.mp4', 'left_mp4_path': 'success/2023-06-27/Tue_Jun_27_21:02:21_2023/recordings/MP4/21582473.mp4', 'right_mp4_path': 'success/2023-06-27/Tue_Jun_27_21:02:21_2023/recordings/MP4/28221883.mp4'}\n"
     ]
    }
   ],
   "source": [
    "from utils import xyz_from_uvd, uvd_from_xyz, T_from_xyzrpy, xyzrpy_from_T\n",
    "\n",
    "import glob\n",
    "import json\n",
    "\n",
    "droid_base_path = \"/mnt/20T/droid_raw_1.0.1\"\n",
    "\n",
    "episode_meta_paths = glob.glob(\"*/success/*/*/metadata_*.json\", root_dir=droid_base_path)\n",
    "print(len(episode_meta_paths))\n",
    "\n",
    "def wo_prefix(p):\n",
    "    return \"/\".join(p.split(\"/\")[3:])\n",
    "\n",
    "for episode_meta_path in episode_meta_paths:\n",
    "    with open(droid_base_path + \"/\" + episode_meta_path, \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "        \n",
    "    uuid = metadata[\"uuid\"]\n",
    "    \n",
    "    if uuid not in cam2base_extrinsic_superset:\n",
    "        print(f\"uuid {uuid} not in cam2base_extrinsic_superset\")\n",
    "        continue\n",
    "    \n",
    "    prefix_path = \"/\".join(episode_meta_path.split(\"/\")[:-1])\n",
    "    \n",
    "    print(uuid)\n",
    "    print(prefix_path)\n",
    "    print(metadata)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytransform3d.transformations as pt\n",
    "import numpy as np\n",
    "\n",
    "Tbase2cam = pt.invert_transform(T_from_xyzrpy(cam2base_extrinsic_superset[uuid][metadata[\"ext1_cam_serial\"]]))\n",
    "\n",
    "Teef2tip = np.array([\n",
    "    [0, 0, 1, 0],\n",
    "    [0, -1, 0, 0],\n",
    "    [1, 0, 0, 0.150],\n",
    "    [0, 0, 0, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "cartesian_positions = None\n",
    "\n",
    "with h5py.File(droid_base_path + \"/\" + prefix_path + \"/\" + wo_prefix(metadata[\"hdf5_path\"]), \"r\") as f:\n",
    "    cartesian_positions = np.array(f[\"observation\"][\"robot_state\"][\"cartesian_position\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = h5py.File(droid_base_path + \"/\" + prefix_path + \"/\" + wo_prefix(metadata[\"hdf5_path\"]), \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f['action'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyzed.sl as sl\n",
    "\n",
    "def load_svo(svo_path, frame_max=None, frame_step=1):\n",
    "    # Create a ZED camera object\n",
    "    zed = sl.Camera()\n",
    "    \n",
    "    # Set configuration parameters\n",
    "    init_params = sl.InitParameters()\n",
    "    init_params.set_from_svo_file(svo_path)\n",
    "    \n",
    "    # Open the camera\n",
    "    err = zed.open(init_params)\n",
    "    if err != sl.ERROR_CODE.SUCCESS:\n",
    "        print(f\"Error {err}: Failed to open SVO file\")\n",
    "        return\n",
    "    \n",
    "    # Print camera info\n",
    "    cam_info = zed.get_camera_information()\n",
    "    fps = round(cam_info.camera_configuration.fps)\n",
    "    height = round(cam_info.camera_configuration.resolution.height)\n",
    "    width = round(cam_info.camera_configuration.resolution.width)\n",
    "    print(\"ZED Model                 : {0}\".format(cam_info.camera_model))\n",
    "    print(\"ZED Serial Number         : {0}\".format(cam_info.serial_number))\n",
    "    print(\"ZED Camera Firmware       : {0}/{1}\".format(cam_info.camera_configuration.firmware_version, cam_info.sensors_configuration.firmware_version))\n",
    "    print(\"ZED Camera Resolution     : {0}x{1}\".format(width, height))\n",
    "    print(\"ZED Camera FPS            : {0}\".format(fps))\n",
    "    \n",
    "    # Get intrinsics\n",
    "    left_cam_calibration_params = zed.get_camera_information().camera_configuration.calibration_parameters.left_cam\n",
    "    fx = left_cam_calibration_params.fx\n",
    "    fy = left_cam_calibration_params.fy\n",
    "    cx = left_cam_calibration_params.cx\n",
    "    cy = left_cam_calibration_params.cy\n",
    "    intrinsics = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n",
    "    depth_scale = 1000\n",
    "    \n",
    "    yield intrinsics, depth_scale, fps, height, width\n",
    "    \n",
    "    # Create image\n",
    "    image = sl.Mat()\n",
    "    depth = sl.Mat()\n",
    "    # point_cloud = sl.Mat()\n",
    "    \n",
    "    # Read frames\n",
    "    frame_idx = 0\n",
    "    while zed.grab() == sl.ERROR_CODE.SUCCESS:\n",
    "        if frame_idx % frame_step == 0:\n",
    "            zed.retrieve_image(image, sl.VIEW.LEFT) # Retrieve image\n",
    "            zed.retrieve_measure(depth, sl.MEASURE.DEPTH) # Retrieve depth\n",
    "            # zed.retrieve_measure(point_cloud, sl.MEASURE.XYZRGBA)\n",
    "            \n",
    "            # zed.retrieve_image(image_r, sl.VIEW.RIGHT) # Retrieve right image\n",
    "            # zed.retrieve_measure(depth_r, sl.MEASURE.DEPTH_RIGHT) # Retrieve right depth\n",
    "            # zed.retrieve_measure(point_cloud_r, sl.MEASURE.XYZRGBA_RIGHT)\n",
    "\n",
    "            # Convert to numpy array\n",
    "            image_array = image.get_data().copy() # 不加copy好像会导致内存泄漏\n",
    "            depth_array = depth.get_data().copy()\n",
    "            # point_cloud_array = point_cloud.get_data().copy()\n",
    "            \n",
    "            a = yield frame_idx, image_array, depth_array\n",
    "            \n",
    "            if frame_max is not None and frame_idx == frame_max:\n",
    "                break\n",
    "        \n",
    "        frame_idx += 1\n",
    "    \n",
    "    # Close the camera\n",
    "    zed.close()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils_cv import draw_xyz_axis\n",
    "\n",
    "# g = load_svo(droid_base_path + \"/\" + prefix_path + \"/\" + wo_prefix(metadata[\"ext1_svo_path\"]))\n",
    "\n",
    "# for idx, (image_array, depth_array, intrinsics, depth_scale) in enumerate(g):\n",
    "#     image_array = cv2.cvtColor(np.asarray(image_array), cv2.COLOR_BGRA2BGR)\n",
    "#     depth_array = depth_array.astype(np.uint16)\n",
    "    \n",
    "#     Ttip2base = T_from_xyzrpy(cartesian_positions[idx])\n",
    "#     Ttip2cam = Tbase2cam @ Ttip2base\n",
    "#     Teef2cam = Ttip2cam @ Teef2tip\n",
    "    \n",
    "#     break\n",
    "\n",
    "# from pytorch3d.transforms import so3_log_map, so3_exp_map, se3_log_map, se3_exp_map\n",
    "# import pytransform3d.transformations as pt\n",
    "# import pytransform3d.rotations as pr\n",
    "# import torch\n",
    "\n",
    "# print(Teef2cam)\n",
    "# axis_angle = so3_log_map(torch.tensor(Teef2cam[np.newaxis, :3,:3]))\n",
    "# print(axis_angle)\n",
    "# T = so3_exp_map(axis_angle)\n",
    "# print(T)\n",
    "\n",
    "# print(pr.compact_axis_angle_from_matrix(Teef2cam[:3,:3]))\n",
    "\n",
    "# print(se3_log_map(torch.tensor(Teef2cam.T[np.newaxis, :, :])))\n",
    "# print(pt.exponential_coordinates_from_transform(Teef2cam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZED Model                 : ZED 2\n",
      "ZED Serial Number         : 21582473\n",
      "ZED Camera Firmware       : 1523/776\n",
      "ZED Camera Resolution     : 1280x720\n",
      "ZED Camera FPS            : 60\n",
      "[2025-06-19 13:31:24 UTC][ZED][INFO] Logging level INFO\n",
      "[2025-06-19 13:31:24 UTC][ZED][INFO] Logging level INFO\n",
      "[2025-06-19 13:31:24 UTC][ZED][INFO] Logging level INFO\n",
      "[2025-06-19 13:31:24 UTC][ZED][INFO] [Init]  Depth mode: PERFORMANCE\n",
      "[2025-06-19 13:31:24 UTC][ZED][INFO] [Init]  Serial Number: S/N 21582473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2430467/2661826312.py:9: RuntimeWarning: invalid value encountered in cast\n",
      "  depth_array = depth_array.astype(np.uint16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-19 13:31:34 UTC][ZED][WARNING] END OF SVO FILE REACHED in sl::ERROR_CODE sl::Camera::grab(sl::RuntimeParameters)\n"
     ]
    }
   ],
   "source": [
    "from utils_cv import draw_xyz_axis\n",
    "\n",
    "g = load_svo(droid_base_path + \"/\" + prefix_path + \"/\" + wo_prefix(metadata[\"ext1_svo_path\"]), frame_step=10)\n",
    "\n",
    "intrinsics, depth_scale, fps, height, width = next(g)\n",
    "\n",
    "for frame_idx, image_array, depth_array in g:\n",
    "    image_array = cv2.cvtColor(np.asarray(image_array), cv2.COLOR_BGRA2BGR)\n",
    "    depth_array = depth_array.astype(np.uint16)\n",
    "    \n",
    "    Ttip2base = T_from_xyzrpy(cartesian_positions[frame_idx])\n",
    "    Ttip2cam = Tbase2cam @ Ttip2base\n",
    "    Teef2cam = Ttip2cam @ Teef2tip\n",
    "    \n",
    "    viewer.update(image_array, depth_array, intrinsics, Teef2cam)\n",
    "    \n",
    "    image_array_with_axis = draw_xyz_axis(image_array, ob_in_cam=Teef2cam, scale=0.1, K=intrinsics, thickness=3, transparency=0)\n",
    "    \n",
    "    # cv2.imshow(\"image\", image_array)\n",
    "    depth_colored = cv2.applyColorMap(cv2.convertScaleAbs(depth_array / depth_scale, alpha=100), cv2.COLORMAP_JET)\n",
    "    # cv2.imshow(\"depth_colored\", depth_colored)\n",
    "    cv2.imshow(\"image\", np.vstack((cv2.resize(image_array_with_axis, (0, 0), fx=0.5, fy=0.5), cv2.resize(depth_colored, (0, 0), fx=0.5, fy=0.5))))\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "viewer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
